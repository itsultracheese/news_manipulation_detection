{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "bert_sentence_level.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9af243bf6b234586b34c849d03656d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d239738a0ffa49f7a9519a7ed5f7100d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b52bf670334f47ab93f9477b4648d5ab",
              "IPY_MODEL_b9f7868cbc3e4098bd1d19417d15ce4c",
              "IPY_MODEL_560d93583aaf4a229f2b10316040f387"
            ]
          }
        },
        "d239738a0ffa49f7a9519a7ed5f7100d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b52bf670334f47ab93f9477b4648d5ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_74f56aaf210643cdb5f598bb4cecd67b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_999fa8065ac947fc9f5d79d40bdfda5f"
          }
        },
        "b9f7868cbc3e4098bd1d19417d15ce4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_897dd32fadab4b21b75ee5bf84284af5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 249,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 249,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_570b8a8bf21042b1a2e49ce7cf2c18f6"
          }
        },
        "560d93583aaf4a229f2b10316040f387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_938fc8e48215411ca709bf35b95ee9b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 249/249 [04:12&lt;00:00,  1.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c60cb2ab8a347bea94f074f0389bf1b"
          }
        },
        "74f56aaf210643cdb5f598bb4cecd67b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "999fa8065ac947fc9f5d79d40bdfda5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "897dd32fadab4b21b75ee5bf84284af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "570b8a8bf21042b1a2e49ce7cf2c18f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "938fc8e48215411ca709bf35b95ee9b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c60cb2ab8a347bea94f074f0389bf1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A5mZyfEVPwx"
      },
      "source": [
        "Ссылка на файл с обученной моделью: https://drive.google.com/file/d/1-98eC_25fcy8HZUwTQ70Oz_0oa5UxsgC/view?usp=sharing"
      ],
      "id": "6A5mZyfEVPwx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvqN-XhSqXgZ",
        "outputId": "bd532e0b-5073-4d47-9d04-20d8eabc3b2d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "kvqN-XhSqXgZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRsPWMJ1q4G1",
        "outputId": "e3d13e9a-db38-4e6b-81ed-327a679ab8a8"
      },
      "source": [
        "! pip install transformers"
      ],
      "id": "rRsPWMJ1q4G1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 12.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 37.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 38.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 41.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-10T18:04:25.155422Z",
          "start_time": "2021-10-10T18:04:19.945650Z"
        },
        "id": "48353302"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import codecs\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from tqdm.notebook import tqdm"
      ],
      "id": "48353302",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-10T18:04:40.011039Z",
          "start_time": "2021-10-10T18:04:39.995035Z"
        },
        "id": "99b5aac5"
      },
      "source": [
        "def read_articles_from_file_list(folder_name, file_pattern=\"*.txt\"):\n",
        "    '''\n",
        "    Read articles from files matching patterns <file_pattern> from  \n",
        "    the directory <folder_name>. \n",
        "    The content of the article is saved in the dictionary whose key\n",
        "    is the id of the article (extracted from the file name).\n",
        "    Each element of <sentence_list> is one line of the article.\n",
        "    '''\n",
        "    file_list = glob.glob(os.path.join(folder_name, file_pattern))\n",
        "    articles = {}\n",
        "    article_id_list, sentence_id_list, sentence_list = ([], [], [])\n",
        "    for filename in sorted(file_list):\n",
        "        article_id = os.path.basename(filename).split('.')[0][7:]\n",
        "        with codecs.open(filename, 'r', encoding='utf8') as f:\n",
        "            articles[article_id] = f.read()\n",
        "    return articles\n",
        "\n",
        "def read_predictions_from_file(filename):\n",
        "    '''\n",
        "    Reader for the gold file and the template output file. \n",
        "    Return values are four arrays with article ids, labels \n",
        "    (or ? in the case of a template file), begin of a fragment, \n",
        "    end of a fragment. \n",
        "    '''\n",
        "    articles_id, span_starts, span_ends, gold_labels = ([], [], [], [])\n",
        "    with open(filename, 'r') as f:\n",
        "        for row in f.readlines():\n",
        "            article_id, gold_label, span_start, span_end = row.rstrip().split('\\t')\n",
        "            articles_id.append(article_id)\n",
        "            gold_labels.append((gold_label, int(span_start), int(span_end)))\n",
        "    return articles_id, gold_labels"
      ],
      "id": "99b5aac5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-10T18:09:51.232120Z",
          "start_time": "2021-10-10T18:09:51.208651Z"
        },
        "id": "7e69f819"
      },
      "source": [
        "def label(text, gt_labels):\n",
        "    tokens = []\n",
        "    labels = []\n",
        "    special_symbols = \"\"\"!\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~ \\n\\t\\'\\\\\"\"\"\n",
        "    sentence = []\n",
        "    sent_labels = []\n",
        "    word = ''\n",
        "    inside = False\n",
        "    word_start = 0\n",
        "    for i in range(len(text)):\n",
        "        if text[i] in special_symbols:\n",
        "            if len(word) > 1:\n",
        "                sentence.append(word)\n",
        "                word = ''\n",
        "                if inside:\n",
        "                    sent_labels.append(1)\n",
        "                else:\n",
        "                    sent_labels.append(0)\n",
        "                # if the sentence has ended\n",
        "                if text[i] in \"!.?\\n\" and (i < len(text) - 2 and not (text[i+1].islower() or text[i+2].islower())):\n",
        "                    if len(sentence) > 1:\n",
        "                        tokens.append(sentence)\n",
        "                        if any(sent_labels):\n",
        "                            labels.append(1)\n",
        "                        else:\n",
        "                            labels.append(0)\n",
        "                        sentence = []\n",
        "                        sent_labels = []\n",
        "        else:\n",
        "            if len(word) == 0:\n",
        "                word_start = i\n",
        "            word += text[i]\n",
        "        if len(gt_labels) > 0:\n",
        "            if i == gt_labels[0][1]:\n",
        "                inside = True\n",
        "            elif i == gt_labels[0][2] + 1:\n",
        "                inside = False\n",
        "                gt_labels.pop(0)\n",
        "    return tokens, labels\n",
        "    \n",
        "\n",
        "def create_dataset(path_to_articles, path_to_labels):\n",
        "    '''\n",
        "    Creates the dataset from the files contained in 'datasets/train-articles/' folder\n",
        "    \n",
        "    texts : list, each represents one article and contains\n",
        "    '''\n",
        "    texts = []\n",
        "    labels = []\n",
        "    articles = read_articles_from_file_list(path_to_articles)\n",
        "    article_names = list(articles.keys())\n",
        "    prefix_lbl = path_to_labels + '/article'\n",
        "    postfix_lbl = '.task-flc-tc.labels'\n",
        "    for name in article_names:\n",
        "        articles_id, gold_labels = read_predictions_from_file(prefix_lbl + name + postfix_lbl)\n",
        "        gt_labels = []\n",
        "        for i in range(len(gold_labels)):\n",
        "            if gold_labels[i][0] == 'Loaded_Language':\n",
        "                gt_labels.append(gold_labels[i])\n",
        "        gt_labels.sort(key=lambda x: x[1])\n",
        "        tokens, lbls = label(articles[name], gt_labels)\n",
        "        texts.extend(tokens)\n",
        "        labels.extend(lbls)\n",
        "    \n",
        "    return texts, labels, article_names"
      ],
      "id": "7e69f819",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-10T18:29:32.548341Z",
          "start_time": "2021-10-10T18:29:32.532934Z"
        },
        "id": "17e6b5a8"
      },
      "source": [
        "class ManipulationDataset(Dataset):\n",
        "    def __init__(self, articles_dir, labels_dir, max_seq_len=50):\n",
        "        self.articles_dir = articles_dir\n",
        "        self.labels_dir = labels_dir\n",
        "        self.texts, self.labels, self.article_names = create_dataset(self.articles_dir, self.labels_dir)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "        self.max_seq_len = max_seq_len\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        tokenized = self.tokenizer.encode_plus(' '.join(self.texts[i]), None, add_special_tokens=True, \n",
        "                                               max_length=self.max_seq_len,pad_to_max_length=True, return_token_type_ids=True)\n",
        "        inputs = torch.tensor(tokenized['input_ids'][:self.max_seq_len])\n",
        "        mask = torch.tensor(tokenized['attention_mask'][:self.max_seq_len])\n",
        "        lbls = [1, 0] if self.labels[i] == 0 else [0, 1]\n",
        "        return inputs, mask, torch.tensor(self.labels[i]), torch.tensor(lbls)"
      ],
      "id": "17e6b5a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-10T18:29:44.813437Z",
          "start_time": "2021-10-10T18:29:32.907588Z"
        },
        "id": "51df8b02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "a4b9dcc32e25480ebae3db80203406fb",
            "d5cc1a906b5544a8a3ca061446413c8d",
            "8c69c06fe16d4611b13144ac771c2895",
            "51432c361358413aa51bd659cc21f439"
          ]
        },
        "outputId": "e91fdc43-4d2b-44d2-ce7f-c6d4b4133c7d"
      },
      "source": [
        "root = 'drive/MyDrive/manipulation_dataset/'\n",
        "train_data = ManipulationDataset(root + 'train-articles', root + 'train-labels-task-flc-tc')\n",
        "test_data = ManipulationDataset(root + 'dev-articles', root + 'dev-labels-task-flc-tc')"
      ],
      "id": "51df8b02",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4b9dcc32e25480ebae3db80203406fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/972k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5cc1a906b5544a8a3ca061446413c8d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c69c06fe16d4611b13144ac771c2895",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.87M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51432c361358413aa51bd659cc21f439",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-10T18:31:24.212088Z",
          "start_time": "2021-10-10T18:31:24.171136Z"
        },
        "id": "b5b8a3f1"
      },
      "source": [
        "class BERTClassifier(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
        "        \n",
        "    def forward(self, inputs, mask, labels):\n",
        "        out = self.bert(inputs, mask, labels=labels)\n",
        "        return out"
      ],
      "id": "b5b8a3f1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-10T18:31:35.998784Z",
          "start_time": "2021-10-10T18:31:25.898061Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b9e1de1",
        "outputId": "f27d8bc3-a1a2-4d84-b5ec-69dd106fcd0c"
      },
      "source": [
        "model = BERTClassifier()\n",
        "train_loader = DataLoader(train_data, batch_size=64)\n",
        "test_loader = DataLoader(test_data, batch_size=64)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n",
        "loss_func = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([0.5, 5]))"
      ],
      "id": "6b9e1de1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-10T18:31:36.022764Z",
          "start_time": "2021-10-10T18:31:35.998784Z"
        },
        "id": "f7fddf0b"
      },
      "source": [
        "device = 'cuda'\n",
        "model = model.to(device)"
      ],
      "id": "f7fddf0b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-10T18:31:36.038760Z",
          "start_time": "2021-10-10T18:31:36.022764Z"
        },
        "id": "54e66044"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score"
      ],
      "id": "54e66044",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-10T18:31:36.054761Z",
          "start_time": "2021-10-10T18:31:36.038760Z"
        },
        "id": "d50a7f6d"
      },
      "source": [
        "def calculate_metrics(outputs, labels, threshold=0.35):\n",
        "    sm = torch.softmax(outputs, dim=1).cpu().detach()\n",
        "    classes = []\n",
        "    for s in sm:\n",
        "        if s[1] > threshold:\n",
        "            classes.append(1)\n",
        "        else:\n",
        "            classes.append(0)\n",
        "    classes = torch.tensor(classes)\n",
        "    labels = labels.cpu().ravel()\n",
        "    acc = accuracy_score(labels, classes)\n",
        "    pr = precision_score(labels, classes)\n",
        "    rec = recall_score(labels, classes)\n",
        "    f1 = f1_score(labels, classes)\n",
        "    return acc, pr, rec, f1"
      ],
      "id": "d50a7f6d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-10T18:31:36.086783Z",
          "start_time": "2021-10-10T18:31:36.054761Z"
        },
        "id": "00ebd620"
      },
      "source": [
        "def train(model, train_loader, optimizer, loss_func, epoch):\n",
        "    losses = []\n",
        "    model.train()\n",
        "    count = 0\n",
        "    for inputs, mask, labels, labels_for_loss in tqdm(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        mask = mask.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(inputs, mask, labels)['logits']\n",
        "        loss = loss_func(out.cpu(), labels_for_loss.cpu().float())\n",
        "        losses.append(loss.cpu().detach().item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # count += 1\n",
        "        # if count % 1000 == 0 or count == 3970:\n",
        "    torch.save(model, 'model2' + str(epoch) + '.pt')\n",
        "    print(f'Loss = {np.mean(losses)}')\n",
        "    return np.mean(losses)\n",
        "\n",
        "def validate(model, val_loader, loss_func):\n",
        "    losses = []\n",
        "    accs = []\n",
        "    precs = []\n",
        "    recs = []\n",
        "    f1s = []\n",
        "    model.eval()\n",
        "    for inputs, mask, labels, labels_for_loss in tqdm(val_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        mask = mask.to(device)\n",
        "        labels = labels.to(device)\n",
        "        out = model(inputs, mask, labels)['logits']\n",
        "        loss = loss_func(out.cpu(), labels_for_loss.cpu().float())\n",
        "        losses.append(loss.cpu().detach().item())\n",
        "        acc, pr, rec, f1 = calculate_metrics(out, labels)\n",
        "        accs.append(acc)\n",
        "        precs.append(pr)\n",
        "        recs.append(rec)\n",
        "        f1s.append(f1)\n",
        "    return np.mean(losses), np.mean(accs), np.mean(precs), np.mean(recs), np.mean(f1s)"
      ],
      "id": "00ebd620",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2021-10-10T18:31:29.891Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646,
          "referenced_widgets": [
            "9af243bf6b234586b34c849d03656d08",
            "d239738a0ffa49f7a9519a7ed5f7100d",
            "b52bf670334f47ab93f9477b4648d5ab",
            "b9f7868cbc3e4098bd1d19417d15ce4c",
            "560d93583aaf4a229f2b10316040f387",
            "74f56aaf210643cdb5f598bb4cecd67b",
            "999fa8065ac947fc9f5d79d40bdfda5f",
            "897dd32fadab4b21b75ee5bf84284af5",
            "570b8a8bf21042b1a2e49ce7cf2c18f6",
            "938fc8e48215411ca709bf35b95ee9b9",
            "6c60cb2ab8a347bea94f074f0389bf1b",
            "2f12f895baba409a8607172b8560e648",
            "6f9f79532d1542f2ac215a8f1a465b3f",
            "158a55722e67479ab5d0ebd3e8a92ef5",
            "178d29a792b04f7ab939f82ee3f0f737",
            "41878ad6611142fd8af20074b7ee99f0",
            "6b98c1b50c5542e7a43898c36db507a2",
            "657eb7d3b2be4860a7ad81511e3bc4b4",
            "4adf2737b1c145a195a91a03f5f461b7",
            "88f7065adeae4d8e89cc3e3564012aa7"
          ]
        },
        "id": "17632728",
        "outputId": "efacd1fb-14bd-43e4-c0ea-62a84d1d1af6"
      },
      "source": [
        "epoch_num = 5\n",
        "\n",
        "for epoch in range(epoch_num):\n",
        "    train_loss = train(model, train_loader, optimizer, loss_func, epoch)\n",
        "    print(f'Epoch {epoch}:\\ttrain loss = {train_loss}')\n",
        "    test_loss, test_acc, test_prec, test_rec, test_f1 = validate(model, test_loader, loss_func)\n",
        "    print(f'\\tvalidation loss = {test_loss}, accuracy={test_acc}, precision={test_prec}, recall={test_rec}, f1={test_f1}')"
      ],
      "id": "17632728",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9af243bf6b234586b34c849d03656d08",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/249 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss = 0.44184924009813364\n",
            "Epoch 0:\ttrain loss = 0.44184924009813364\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f12f895baba409a8607172b8560e648",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/46 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tvalidation loss = 0.4212140074890593, accuracy=0.8207044314381271, precision=0.3124082042417283, recall=0.6886639326856718, f1=0.4081678591293466\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f9f79532d1542f2ac215a8f1a465b3f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/249 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss = 0.4228650233053778\n",
            "Epoch 1:\ttrain loss = 0.4228650233053778\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "158a55722e67479ab5d0ebd3e8a92ef5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/46 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tvalidation loss = 0.418715308541837, accuracy=0.821383779264214, precision=0.32024291118836146, recall=0.7197616393268567, f1=0.4192224005599634\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "178d29a792b04f7ab939f82ee3f0f737",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/249 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss = 0.4044388478778931\n",
            "Epoch 2:\ttrain loss = 0.4044388478778931\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41878ad6611142fd8af20074b7ee99f0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/46 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tvalidation loss = 0.41680124272470886, accuracy=0.8289524108138239, precision=0.3339578192525118, recall=0.7108244412592238, f1=0.42841411504642185\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b98c1b50c5542e7a43898c36db507a2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/249 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss = 0.3903023344146679\n",
            "Epoch 3:\ttrain loss = 0.3903023344146679\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "657eb7d3b2be4860a7ad81511e3bc4b4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/46 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tvalidation loss = 0.4215393286684285, accuracy=0.8324710841694537, precision=0.33754425793002274, recall=0.7182778574082921, f1=0.43467946712564176\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4adf2737b1c145a195a91a03f5f461b7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/249 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss = 0.3734335567218712\n",
            "Epoch 4:\ttrain loss = 0.3734335567218712\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88f7065adeae4d8e89cc3e3564012aa7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/46 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tvalidation loss = 0.4260818796313327, accuracy=0.8211399108138239, precision=0.3213764360312516, recall=0.7273617083399692, f1=0.42154323454462805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6V3Sn02TaFh"
      },
      "source": [
        "torch.save(model, \"drive/MyDrive/model_044_rec68.pt\")"
      ],
      "id": "j6V3Sn02TaFh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da28c626"
      },
      "source": [
        "import shutil"
      ],
      "id": "da28c626",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NI0hXjpWMgl6",
        "outputId": "413424a6-d6b0-46e9-ca74-8457146f2c58"
      },
      "source": [
        "shutil.move(\"model23.pt\", \"drive/MyDrive/model_04.pt\")"
      ],
      "id": "NI0hXjpWMgl6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'drive/MyDrive/model_04.pt'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mw_S4R-NHQJ"
      },
      "source": [
        ""
      ],
      "id": "2mw_S4R-NHQJ",
      "execution_count": null,
      "outputs": []
    }
  ]
}