{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import random\n",
    "from random import randint\n",
    "\n",
    "import glob\n",
    "import codecs\n",
    "\n",
    "import nltk\n",
    "from nltk import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"/Users/sophie/Downloads/datasets/train-articles\"\n",
    "path_train_labels = \"/Users/sophie/Downloads/datasets/train-labels-task-flc-tc/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files[0][7:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = {}\n",
    "files = os.listdir(path_train)\n",
    "c = 0\n",
    "for fle in files:\n",
    "    i = files[c][7:16]\n",
    "    try:\n",
    "        with open(path_train + '/' + fle, 'r') as f:\n",
    "            articles[i] = f.read()\n",
    "            c += 1\n",
    "\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_articles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-37205e3e9b47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_articles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_articles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_articles' is not defined"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for fle in files:\n",
    "    i = files[cnt][7:16]\n",
    "    train_articles[i] = ('').join(train_articles[i])\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "teg_files = os.listdir(path_train_labels)\n",
    "tegs = {}\n",
    "for file in teg_files:\n",
    "    i = file[7:16]\n",
    "    try:\n",
    "        with open(path_train_labels + file, 'r') as fp:\n",
    "            tegs[i] = fp.read()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list with articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "teg_files = os.listdir(path_train_labels)\n",
    "tegs = {}\n",
    "for file in teg_files:\n",
    "    i = file[7:16]\n",
    "    try:\n",
    "        with open(path_train_labels + file, 'r') as fp:\n",
    "            tegs[i] = fp.read()\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_manipulation(teg):\n",
    "    return teg.split()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701225819\tName_Calling,Labeling\t177\t187\n",
      "701225819\tRepetition\t2689\t2694\n",
      "701225819\tRepetition\t2787\t2792\n",
      "701225819\tLoaded_Language\t2982\t2991\n",
      "701225819\tName_Calling,Labeling\t77\t99\n",
      "701225819\tName_Calling,Labeling\t996\t1019\n",
      "701225819\tLoaded_Language\t2174\t2182\n",
      "701225819\tRepetition\t2747\t2752\n",
      "701225819\tSlogans\t3787\t3804\n",
      "701225819\tName_Calling,Labeling\t3837\t3860\n",
      "701225819\tName_Calling,Labeling\t4606\t4636\n",
      "701225819\tName_Calling,Labeling\t4720\t4739\n",
      "701225819\tAppeal_to_fear-prejudice\t131\t143\n",
      "701225819\tLoaded_Language\t305\t313\n",
      "701225819\tAppeal_to_fear-prejudice\t1201\t1299\n",
      "701225819\tName_Calling,Labeling\t1525\t1551\n",
      "701225819\tLoaded_Language\t1572\t1583\n",
      "701225819\tLoaded_Language\t1767\t1771\n",
      "701225819\tRepetition\t2616\t2621\n",
      "701225819\tLoaded_Language\t3309\t3315\n",
      "701225819\tName_Calling,Labeling\t4268\t4313\n",
      "701225819\tLoaded_Language\t5914\t5927\n",
      "701225819\tLoaded_Language\t6102\t6112\n",
      "701225819\tName_Calling,Labeling\t111\t143\n",
      "701225819\tAppeal_to_fear-prejudice\t1493\t1605\n",
      "701225819\tName_Calling,Labeling\t1872\t1889\n",
      "701225819\tSlogans\t1967\t1987\n",
      "701225819\tName_Calling,Labeling\t2798\t2811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tegs['701225819'].split('\\n'):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "for k in tegs.keys():\n",
    "    for s in tegs[k].split('\\n'):\n",
    "        if s != '':\n",
    "            try: \n",
    "                d[take_manipulation(s)] += 1\n",
    "            except KeyError:\n",
    "                d[take_manipulation(s)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Loaded_Language': 2123,\n",
       " 'Name_Calling,Labeling': 1058,\n",
       " 'Flag-Waving': 229,\n",
       " 'Repetition': 621,\n",
       " 'Whataboutism,Straw_Men,Red_Herring': 107,\n",
       " 'Exaggeration,Minimisation': 466,\n",
       " 'Appeal_to_fear-prejudice': 294,\n",
       " 'Appeal_to_Authority': 144,\n",
       " 'Doubt': 493,\n",
       " 'Slogans': 129,\n",
       " 'Bandwagon,Reductio_ad_hitlerum': 72,\n",
       " 'Causal_Oversimplification': 209,\n",
       " 'Thought-terminating_Cliches': 76,\n",
       " 'Black-and-White_Fallacy': 107}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d #сколько строчек с такими значениями??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_1 = {d[k] : k for k in d.keys()} \n",
    "sorted_k = sorted(list(d_1.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2123: 'Loaded_Language',\n",
       " 1058: 'Name_Calling,Labeling',\n",
       " 229: 'Flag-Waving',\n",
       " 621: 'Repetition',\n",
       " 107: 'Black-and-White_Fallacy',\n",
       " 466: 'Exaggeration,Minimisation',\n",
       " 294: 'Appeal_to_fear-prejudice',\n",
       " 144: 'Appeal_to_Authority',\n",
       " 493: 'Doubt',\n",
       " 129: 'Slogans',\n",
       " 72: 'Bandwagon,Reductio_ad_hitlerum',\n",
       " 209: 'Causal_Oversimplification',\n",
       " 76: 'Thought-terminating_Cliches'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tegs['763260610'].split('\\n')[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for t in tegs.keys():\n",
    "    if 'Loaded_Language' in [take_manipulation(z) for z in tegs[t].split('\\n')[:-1]]:\n",
    "        c+=1 #спросить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for t in tegs.keys():\n",
    "    if 'Exaggeration,Minimisation' in [take_manipulation(z) for z in tegs[t].split('\\n')[:-1]]:\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_borders(num, articles):\n",
    "    art = articles[num]\n",
    "    t = tegs[str(num)]\n",
    "    b = []\n",
    "    mans = []\n",
    "    for s in t.split('\\n'):\n",
    "        if s != '':\n",
    "            b.append([int(s.split()[2]),int(s.split()[3])])\n",
    "            mans.append(take_manipulation(s))\n",
    "    if len(b) != 0:\n",
    "        res_art = ''\n",
    "        prev_last = 0\n",
    "        for i in range(len(b)):\n",
    "            res_art += art[prev_last:b[i][0]]\n",
    "            manipulation = '     !!!{' + art[b[i][0]:b[i][1]] + '}!!!   (MANIPULATION: ' + mans[i] + ')'\n",
    "            res_art += manipulation\n",
    "            prev_last = b[i][1] \n",
    "        \n",
    "    return res_art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_borders('695833178', articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_articles['701225819']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the greatest leader in modern Western history'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['701225819'][4268:4313]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание функции случайного распределения 0, 1, 2 по каждой новостной статье"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_(train, files_txt):\n",
    "    n = 0\n",
    "    rand = {}\n",
    "    for fle in files:\n",
    "        sen = []\n",
    "        i = files[n][7:16]\n",
    "        for word in range(len(train[i].split())+1):\n",
    "            sen.append(random.randint(0, 2))\n",
    "        rand[i] = sen\n",
    "        n += 1\n",
    "    return rand\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_(articles, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machin'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem('machines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(articles, labels):\n",
    "    labels_stem = []\n",
    "    articles_stem = []\n",
    "    sents = 0\n",
    "    for article in articles:\n",
    "        article_stem = []\n",
    "        label_stem = []\n",
    "        for word in article:\n",
    "            if word.lower() not in stopwords:\n",
    "                cnt = article.index(word.lower())\n",
    "                label_stem.append(labels[sents][cnt]) \n",
    "                word_new = porter.stem(word.lower())\n",
    "                article_stem.append(word_new)\n",
    "        labels_stem.append(label_stem)\n",
    "        articles_stem.append(article_stem)\n",
    "        sents += 1 \n",
    "    return articles_stem, labels_stem \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [[0, 4, 5, 1], [3, 5, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = [['hello', 'mommies', 'a', 'kitties'], ['papa', 'rory', 'cats']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['hello', 'mommi', 'kitti'], ['papa', 'rori', 'cat']],\n",
       " [[0, 4, 1], [3, 5, 6]])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem(ss, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['701225819'].split()\n",
    "l = ''\n",
    "for word in articles['701225819'].split():\n",
    "            word = porter.stem(word.lower())\n",
    "            l += ' ' + word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
