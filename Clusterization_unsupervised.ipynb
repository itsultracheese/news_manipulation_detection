{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clusterization_unsupervised.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_TT3QlE5-YP"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from preprocessing import stem_, stem, create_dataset\n",
        "import numpy as np\n",
        "import joblib\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
        "from distances import Cosine_measure_to_chain_av, Euclidian_measure_to_chain_av,  Manhattan_measure_to_chain_av"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tex2DyBX6N5h"
      },
      "source": [
        "# multilingial embedings dictionary\n",
        "new_multi_dict = joblib.load('letter_mult_emb_2.pkl') \n",
        "'''\n",
        "файл лежит в папке \n",
        "https://drive.google.com/drive/folders/1kIJmDcmSLBql-f3mh_ASfswPWSdMkaPj?usp=sharing \n",
        "'''\n",
        "\n",
        "# thresholds dict for 3 distance metrics\n",
        "thresholds = joblib.load('metric_experiment_result_load_lang.pkl')\n",
        "# metric_experiment_result_load_lang.pkl для only load_lang\n",
        "# metric_experiment_result.pkl для load_lang + labeling\n",
        "\n",
        "# корпус из слуайных предложений словаря Ангелины\n",
        "cluster = joblib.load('angels_cluster_load_lang.pkl')\n",
        "# angels_cluster_load_lang.pkl для only load_lang\n",
        "# angels_cluster.pkl для load_lang + labeling\n",
        "\n",
        "\n",
        "def get_word(w):  \n",
        "    # function for getting words from dictionary\n",
        "    try:  \n",
        "        for line in new_multi_dict[w[0].lower()][len(w)]:\n",
        "            vec = line.split()\n",
        "            word = vec[0]\n",
        "            if w == word:\n",
        "                vector = list(map(lambda x: float(x), vec[1:]))\n",
        "                return vector\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def make_preds(sentence):\n",
        "    # predictions for sentence\n",
        "    new_sentence = list(map(lambda x: get_word(x.lower()), sentence))\n",
        "    new_sentence = np.array([x for x in new_sentence if x is not None]).mean(axis=0)\n",
        "\n",
        "    preds_cos = Cosine_measure_to_chain_av(cluster, new_sentence) <= thresholds['cos'][0]\n",
        "    preds_euc = Euclidian_measure_to_chain_av(cluster, new_sentence) <= thresholds['euc'][0]\n",
        "    preds_manh = Manhattan_measure_to_chain_av(cluster, new_sentence) <= thresholds['manh'][0]\n",
        "\n",
        "    return {'cos': int(preds_cos), 'euc': int(preds_euc), 'manh': int(preds_manh)}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}