{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "sentences = np.load('bert_sentence_embeddings.npy')\n",
    "labels = np.load('labels.npy')\n",
    "\n",
    "X_train, x_test, y_train, y_test = train_test_split(sentences, labels, test_size=0.2, shuffle=True)\n",
    "weights = compute_class_weight(class_weight='balanced',classes=np.array([0,1]), y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sergei\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(class_weight='balanced', max_iter=10000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SupVecMach = SVC(class_weight='balanced', max_iter=10000)\n",
    "SupVecMach.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[-1.32016405e-01 -2.26646774e-02  2.95227766e-02 -4.13477659e-01\n -2.62342066e-01 -1.87187821e-01 -3.06831598e-02  2.16276534e-02\n -3.56795907e-01  8.47115740e-02 -9.11291018e-02  3.67530823e-01\n  1.54254287e-01  1.42787220e-02 -1.03594765e-01  2.22146228e-01\n -1.27699912e-01 -3.85306358e-01  2.37974793e-01  2.53502637e-01\n -5.35000872e-04 -1.09213427e-01  1.88204601e-01 -2.23407894e-01\n  1.96495540e-02  5.55658415e-02  1.75840139e-01  2.67879125e-02\n  6.34018332e-02 -1.80287346e-01  6.81447834e-02 -3.48761491e-02\n  2.02684119e-01  7.04122931e-02  1.62722677e-01  2.95628250e-01\n -5.27098426e-04  3.51266004e-02 -2.11192846e-01 -1.25499845e-01\n -8.12186748e-02  1.69753972e-02  6.27878308e-01  1.95904210e-01\n -6.86260462e-02  3.48171294e-01 -1.73936859e-01 -1.79413453e-01\n -5.94706655e-01  1.66652396e-01  4.90811802e-02  1.39832705e-01\n  2.28145272e-02 -5.79080462e-01  3.92236710e-01  2.23596603e-01\n -7.96102267e-03  5.40057898e-01 -3.04943998e-03  1.96359605e-02\n  3.79326075e-01  1.78273886e-01 -1.92172214e-01 -2.49678329e-01\n  1.29172713e-01  3.38821262e-02  2.23845959e-01 -1.32111311e-01\n  6.49740845e-02  2.24955268e-02 -2.33294755e-01  1.60621494e-01\n -2.11346790e-01 -2.32447580e-01  2.52018809e-01  3.64945978e-01\n -4.72196117e-02  1.78392529e-01  1.54590353e-01 -5.17141402e-01\n  3.03092897e-01  2.45569080e-01 -1.40800998e-01 -4.17198241e-02\n -1.62134647e-01 -2.04344224e-02  2.78827220e-01  1.38264105e-01\n  3.83149773e-01  2.84698308e-01  1.39343560e-01 -1.81476608e-01\n -4.96628359e-02 -2.60134697e-01 -2.20848605e-01  2.85661370e-01\n  1.50676295e-01  1.41760319e-01 -2.88929343e-01  2.69263059e-01\n -8.16166550e-02  7.36273974e-02 -2.25749224e-01 -2.54759163e-01\n -1.36669546e-01 -1.49144884e-02 -3.11296079e-02  5.13479523e-02\n -4.14898574e-01 -2.40466326e-01  2.85067022e-01  3.72056395e-01\n -1.89937770e-01 -1.75358340e-01 -9.20019373e-02 -1.97400719e-01\n -9.56849530e-02  2.39839703e-02 -1.03693604e-01  1.48623496e-01\n -1.78044420e-02  8.31038952e-02  1.68934409e-02  1.64750993e-01\n -5.50442934e-02 -6.90871701e-02 -2.88217366e-01  1.13062680e-01\n -1.78542346e-01 -1.29458636e-01  5.90543437e-04  3.28414589e-01\n -3.56090605e-01  5.15325777e-02  1.89908341e-01 -2.57779323e-02\n  1.41531110e-01 -1.48367018e-01 -8.72477517e-02 -2.37423807e-01\n -2.63621397e-02  2.30551332e-01  4.38398898e-01  1.00514546e-01\n -1.62386864e-01  1.07586067e-02  1.78857267e-01 -1.20439366e-01\n -1.38262838e-01  2.58112282e-01  1.31889462e-01 -4.31727320e-01\n  2.50589997e-01  4.98393252e-02 -2.54321732e-02  3.87371704e-02\n -1.24704912e-01 -2.42397740e-01  1.15261532e-01  2.71047831e-01\n -2.03103393e-01  3.65872085e-01  2.59994835e-01  4.84321192e-02\n  2.16463238e-01 -5.04741296e-02  3.11529096e-02 -1.48957148e-01\n  1.87937871e-01  3.03800590e-02 -7.81212896e-02 -4.69860882e-02\n -1.38400853e-01 -1.08718202e-01  1.84933111e-01 -2.37404153e-01\n -3.55486512e-01 -2.57878661e-01  4.35686767e-01  1.11457720e-01\n  3.19475979e-01 -3.70430291e-01  1.73113674e-01  2.69123111e-02\n  1.55942842e-01  5.86799085e-02  2.49244124e-01  4.79479134e-01\n -2.02995852e-01 -1.85909212e-01  5.90947382e-02  2.96694994e-01\n  1.28971606e-01  8.90615061e-02 -4.28031087e-02 -3.48659337e-01\n  2.23951608e-01  1.71925083e-01  8.36495161e-02 -2.98011601e-01\n -1.44433886e-01 -1.84499383e-01 -5.67839265e-01 -3.53692030e-03\n -3.87008153e-02 -1.44552812e-01 -2.34226778e-01 -4.74067599e-01\n -1.95107415e-01  9.40984488e-02  6.68789893e-02  1.26096010e-01\n -8.50963891e-02 -4.93036434e-02 -2.23841041e-01  6.24479167e-02\n -6.48995414e-02  2.52465099e-01 -1.40074998e-01  1.90644696e-01\n  9.71021056e-02  3.08459587e-02  5.45114987e-02 -4.51272160e-01\n -4.29362357e-01  5.59070185e-02 -5.93150556e-02  1.29291117e-02\n  4.08304743e-02  4.68945131e-02 -5.12596786e-01 -3.19716930e-01\n  1.38340995e-01 -1.56169338e-02 -2.30743483e-01 -3.23003381e-01\n -1.80536181e-01  2.62750294e-02 -3.17873716e-01 -2.93844014e-01\n  4.56066057e-02 -2.83969551e-01  1.80485278e-01  5.78770065e-04\n  1.64377540e-01  3.43737379e-02 -2.22081155e-01  2.61973053e-01\n  1.67394474e-01  3.46409023e-01  1.45919593e-02 -4.45076227e-01\n -2.79902756e-01 -2.20380470e-01 -1.46586567e-01 -2.59851754e-01\n  1.79183453e-01  3.07809025e-01  2.70884693e-01  1.88497692e-01\n  2.68518683e-02 -3.01879942e-02 -3.19271803e-01  1.06116310e-01\n  2.10746124e-01 -5.44957519e-01 -3.20507258e-01  1.52757913e-01\n  7.89546594e-02 -6.89351335e-02 -1.36621445e-01 -5.17010167e-02\n  2.59602934e-01  2.74302423e-01  2.21203521e-01 -6.84680790e-02\n -8.67813304e-02 -4.95104611e-01 -1.70381755e-01  1.27958000e-01\n -1.11802313e-02 -1.73422486e-01  5.20775437e-01  1.98757812e-01\n  2.04627663e-01  5.87754417e-03 -2.60740370e-02 -2.79114485e-01\n -4.38996665e-02  1.87621906e-01 -4.36557904e-02 -1.32019103e-01\n -4.75526527e-02  1.54017657e-01 -6.52264357e-02 -4.09178622e-02\n -3.16172749e-01  3.72046798e-01  1.03867296e-02  1.68215513e-01\n  6.87061772e-02 -1.62585810e-01  1.61217794e-01  3.51506650e-01\n -8.98637921e-02 -1.42806824e-02  2.00146392e-01  3.49619687e-01\n  2.18054980e-01  1.17147878e-01  9.32226554e-02 -7.35127479e-02\n -9.06057134e-02  2.13865831e-01  2.00117111e-01 -9.52750415e-05\n -7.93316141e-02  4.03100491e-01  2.30842918e-01 -4.13939297e-01\n  3.95149738e-02  1.75504386e-01 -4.52108383e-01  3.31716388e-01\n  2.89189190e-01 -2.36328989e-01  1.13477454e-01  5.68667948e-02\n  4.21697289e-01  1.76858500e-01  1.26429349e-01 -8.71957242e-02\n -6.75192699e-02  8.31621438e-02  1.20184757e-01  7.62588531e-02\n -4.16578442e-01  9.09143314e-02 -5.10740221e-01 -1.75549254e-01\n  2.49059826e-01  1.31826445e-01 -4.00992334e-02 -1.08842276e-01\n -1.80381611e-01 -1.09333254e-01  2.54195243e-01  2.22328514e-01\n -2.28400514e-01 -1.03032991e-01 -2.23136380e-01 -2.00304821e-01\n -4.22336049e-02 -4.77253534e-02  4.33186963e-02  2.02105552e-01\n  1.92141682e-02  1.07934624e-02  4.27458376e-01  8.33522528e-02\n -1.72994509e-01  2.74554908e-01 -2.73620218e-01  3.86379868e-01\n -2.87424680e-02  4.48795743e-02 -2.90863931e-01  9.10533518e-02\n -7.81572536e-02  5.26067009e-03  1.57569528e-01  6.47732541e-02\n -1.04080915e-01  1.14153326e-01  3.72418463e-01  2.77947247e-01\n -2.22911388e-02 -1.30402688e-02 -3.15519542e-01 -4.60688472e-02\n -3.26157272e-01 -1.58115834e-01 -5.44935465e-05  1.04039386e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b5a785a8ed32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSupVecMach\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \"\"\"\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m             X = check_array(X, accept_sparse='csr', dtype=np.float64,\n\u001b[0m\u001b[0;32m    466\u001b[0m                             order=\"C\", accept_large_sparse=False)\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    617\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    620\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-1.32016405e-01 -2.26646774e-02  2.95227766e-02 -4.13477659e-01\n -2.62342066e-01 -1.87187821e-01 -3.06831598e-02  2.16276534e-02\n -3.56795907e-01  8.47115740e-02 -9.11291018e-02  3.67530823e-01\n  1.54254287e-01  1.42787220e-02 -1.03594765e-01  2.22146228e-01\n -1.27699912e-01 -3.85306358e-01  2.37974793e-01  2.53502637e-01\n -5.35000872e-04 -1.09213427e-01  1.88204601e-01 -2.23407894e-01\n  1.96495540e-02  5.55658415e-02  1.75840139e-01  2.67879125e-02\n  6.34018332e-02 -1.80287346e-01  6.81447834e-02 -3.48761491e-02\n  2.02684119e-01  7.04122931e-02  1.62722677e-01  2.95628250e-01\n -5.27098426e-04  3.51266004e-02 -2.11192846e-01 -1.25499845e-01\n -8.12186748e-02  1.69753972e-02  6.27878308e-01  1.95904210e-01\n -6.86260462e-02  3.48171294e-01 -1.73936859e-01 -1.79413453e-01\n -5.94706655e-01  1.66652396e-01  4.90811802e-02  1.39832705e-01\n  2.28145272e-02 -5.79080462e-01  3.92236710e-01  2.23596603e-01\n -7.96102267e-03  5.40057898e-01 -3.04943998e-03  1.96359605e-02\n  3.79326075e-01  1.78273886e-01 -1.92172214e-01 -2.49678329e-01\n  1.29172713e-01  3.38821262e-02  2.23845959e-01 -1.32111311e-01\n  6.49740845e-02  2.24955268e-02 -2.33294755e-01  1.60621494e-01\n -2.11346790e-01 -2.32447580e-01  2.52018809e-01  3.64945978e-01\n -4.72196117e-02  1.78392529e-01  1.54590353e-01 -5.17141402e-01\n  3.03092897e-01  2.45569080e-01 -1.40800998e-01 -4.17198241e-02\n -1.62134647e-01 -2.04344224e-02  2.78827220e-01  1.38264105e-01\n  3.83149773e-01  2.84698308e-01  1.39343560e-01 -1.81476608e-01\n -4.96628359e-02 -2.60134697e-01 -2.20848605e-01  2.85661370e-01\n  1.50676295e-01  1.41760319e-01 -2.88929343e-01  2.69263059e-01\n -8.16166550e-02  7.36273974e-02 -2.25749224e-01 -2.54759163e-01\n -1.36669546e-01 -1.49144884e-02 -3.11296079e-02  5.13479523e-02\n -4.14898574e-01 -2.40466326e-01  2.85067022e-01  3.72056395e-01\n -1.89937770e-01 -1.75358340e-01 -9.20019373e-02 -1.97400719e-01\n -9.56849530e-02  2.39839703e-02 -1.03693604e-01  1.48623496e-01\n -1.78044420e-02  8.31038952e-02  1.68934409e-02  1.64750993e-01\n -5.50442934e-02 -6.90871701e-02 -2.88217366e-01  1.13062680e-01\n -1.78542346e-01 -1.29458636e-01  5.90543437e-04  3.28414589e-01\n -3.56090605e-01  5.15325777e-02  1.89908341e-01 -2.57779323e-02\n  1.41531110e-01 -1.48367018e-01 -8.72477517e-02 -2.37423807e-01\n -2.63621397e-02  2.30551332e-01  4.38398898e-01  1.00514546e-01\n -1.62386864e-01  1.07586067e-02  1.78857267e-01 -1.20439366e-01\n -1.38262838e-01  2.58112282e-01  1.31889462e-01 -4.31727320e-01\n  2.50589997e-01  4.98393252e-02 -2.54321732e-02  3.87371704e-02\n -1.24704912e-01 -2.42397740e-01  1.15261532e-01  2.71047831e-01\n -2.03103393e-01  3.65872085e-01  2.59994835e-01  4.84321192e-02\n  2.16463238e-01 -5.04741296e-02  3.11529096e-02 -1.48957148e-01\n  1.87937871e-01  3.03800590e-02 -7.81212896e-02 -4.69860882e-02\n -1.38400853e-01 -1.08718202e-01  1.84933111e-01 -2.37404153e-01\n -3.55486512e-01 -2.57878661e-01  4.35686767e-01  1.11457720e-01\n  3.19475979e-01 -3.70430291e-01  1.73113674e-01  2.69123111e-02\n  1.55942842e-01  5.86799085e-02  2.49244124e-01  4.79479134e-01\n -2.02995852e-01 -1.85909212e-01  5.90947382e-02  2.96694994e-01\n  1.28971606e-01  8.90615061e-02 -4.28031087e-02 -3.48659337e-01\n  2.23951608e-01  1.71925083e-01  8.36495161e-02 -2.98011601e-01\n -1.44433886e-01 -1.84499383e-01 -5.67839265e-01 -3.53692030e-03\n -3.87008153e-02 -1.44552812e-01 -2.34226778e-01 -4.74067599e-01\n -1.95107415e-01  9.40984488e-02  6.68789893e-02  1.26096010e-01\n -8.50963891e-02 -4.93036434e-02 -2.23841041e-01  6.24479167e-02\n -6.48995414e-02  2.52465099e-01 -1.40074998e-01  1.90644696e-01\n  9.71021056e-02  3.08459587e-02  5.45114987e-02 -4.51272160e-01\n -4.29362357e-01  5.59070185e-02 -5.93150556e-02  1.29291117e-02\n  4.08304743e-02  4.68945131e-02 -5.12596786e-01 -3.19716930e-01\n  1.38340995e-01 -1.56169338e-02 -2.30743483e-01 -3.23003381e-01\n -1.80536181e-01  2.62750294e-02 -3.17873716e-01 -2.93844014e-01\n  4.56066057e-02 -2.83969551e-01  1.80485278e-01  5.78770065e-04\n  1.64377540e-01  3.43737379e-02 -2.22081155e-01  2.61973053e-01\n  1.67394474e-01  3.46409023e-01  1.45919593e-02 -4.45076227e-01\n -2.79902756e-01 -2.20380470e-01 -1.46586567e-01 -2.59851754e-01\n  1.79183453e-01  3.07809025e-01  2.70884693e-01  1.88497692e-01\n  2.68518683e-02 -3.01879942e-02 -3.19271803e-01  1.06116310e-01\n  2.10746124e-01 -5.44957519e-01 -3.20507258e-01  1.52757913e-01\n  7.89546594e-02 -6.89351335e-02 -1.36621445e-01 -5.17010167e-02\n  2.59602934e-01  2.74302423e-01  2.21203521e-01 -6.84680790e-02\n -8.67813304e-02 -4.95104611e-01 -1.70381755e-01  1.27958000e-01\n -1.11802313e-02 -1.73422486e-01  5.20775437e-01  1.98757812e-01\n  2.04627663e-01  5.87754417e-03 -2.60740370e-02 -2.79114485e-01\n -4.38996665e-02  1.87621906e-01 -4.36557904e-02 -1.32019103e-01\n -4.75526527e-02  1.54017657e-01 -6.52264357e-02 -4.09178622e-02\n -3.16172749e-01  3.72046798e-01  1.03867296e-02  1.68215513e-01\n  6.87061772e-02 -1.62585810e-01  1.61217794e-01  3.51506650e-01\n -8.98637921e-02 -1.42806824e-02  2.00146392e-01  3.49619687e-01\n  2.18054980e-01  1.17147878e-01  9.32226554e-02 -7.35127479e-02\n -9.06057134e-02  2.13865831e-01  2.00117111e-01 -9.52750415e-05\n -7.93316141e-02  4.03100491e-01  2.30842918e-01 -4.13939297e-01\n  3.95149738e-02  1.75504386e-01 -4.52108383e-01  3.31716388e-01\n  2.89189190e-01 -2.36328989e-01  1.13477454e-01  5.68667948e-02\n  4.21697289e-01  1.76858500e-01  1.26429349e-01 -8.71957242e-02\n -6.75192699e-02  8.31621438e-02  1.20184757e-01  7.62588531e-02\n -4.16578442e-01  9.09143314e-02 -5.10740221e-01 -1.75549254e-01\n  2.49059826e-01  1.31826445e-01 -4.00992334e-02 -1.08842276e-01\n -1.80381611e-01 -1.09333254e-01  2.54195243e-01  2.22328514e-01\n -2.28400514e-01 -1.03032991e-01 -2.23136380e-01 -2.00304821e-01\n -4.22336049e-02 -4.77253534e-02  4.33186963e-02  2.02105552e-01\n  1.92141682e-02  1.07934624e-02  4.27458376e-01  8.33522528e-02\n -1.72994509e-01  2.74554908e-01 -2.73620218e-01  3.86379868e-01\n -2.87424680e-02  4.48795743e-02 -2.90863931e-01  9.10533518e-02\n -7.81572536e-02  5.26067009e-03  1.57569528e-01  6.47732541e-02\n -1.04080915e-01  1.14153326e-01  3.72418463e-01  2.77947247e-01\n -2.22911388e-02 -1.30402688e-02 -3.15519542e-01 -4.60688472e-02\n -3.26157272e-01 -1.58115834e-01 -5.44935465e-05  1.04039386e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "SupVecMach.predict(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-65bbc5b4ce0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSupVecMach\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreds_with_tr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    655\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \"\"\"\n\u001b[1;32m--> 657\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[0;32m    625\u001b[0m                                  \" probability=False\")\n\u001b[0;32m    626\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'c_svc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nu_svc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "proba = SupVecMach.predict_proba(x_test)\n",
    "def preds_with_tr(tr, proba):\n",
    "    pr = proba[:, 1]\n",
    "    ans = (pr>tr).astype(int)\n",
    "    return ans\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "for t in np.arange(0.,1.,0.01):\n",
    "    prediction = preds_with_tr(t, proba)\n",
    "    precisions.append(precision_score(y_test, list(prediction)))\n",
    "    recalls.append(recall_score(y_test, list(prediction)))\n",
    "    f1s.append(f1_score(y_test, list(prediction)))\n",
    "    \n",
    "print('best F1 = ', max(f1s))\n",
    "i = np.array(f1s).argmax()\n",
    "print('precision = ', precisions[i])\n",
    "print('recall = ', recalls[i])\n",
    "\n",
    "\n",
    "plt.figure(figsize = (20,12))\n",
    "plt.grid()\n",
    "plt.title('F1')\n",
    "plt.scatter(np.arange(0.,1.,0.01), f1s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
