{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b622344",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T11:05:46.675584Z",
     "start_time": "2021-10-08T11:05:46.317942Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import codecs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ca19b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T07:03:05.426364Z",
     "start_time": "2021-10-08T07:03:05.402299Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_articles_from_file_list(folder_name, file_pattern=\"*.txt\"):\n",
    "    '''\n",
    "    Read articles from files matching patterns <file_pattern> from  \n",
    "    the directory <folder_name>. \n",
    "    The content of the article is saved in the dictionary whose key\n",
    "    is the id of the article (extracted from the file name).\n",
    "    Each element of <sentence_list> is one line of the article.\n",
    "    '''\n",
    "    file_list = glob.glob(os.path.join(folder_name, file_pattern))\n",
    "    articles = {}\n",
    "    article_id_list, sentence_id_list, sentence_list = ([], [], [])\n",
    "    for filename in sorted(file_list):\n",
    "        article_id = os.path.basename(filename).split('.')[0][7:]\n",
    "        with codecs.open(filename, 'r', encoding='utf8') as f:\n",
    "            articles[article_id] = f.read()\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2e0e9db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T11:00:45.782695Z",
     "start_time": "2021-10-08T11:00:45.767313Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_predictions_from_file(filename):\n",
    "    '''\n",
    "    Reader for the gold file and the template output file. \n",
    "    Return values are four arrays with article ids, labels \n",
    "    (or ? in the case of a template file), begin of a fragment, \n",
    "    end of a fragment. \n",
    "    '''\n",
    "    articles_id, span_starts, span_ends, gold_labels = ([], [], [], [])\n",
    "    with open(filename, 'r') as f:\n",
    "        for row in f.readlines():\n",
    "            article_id, gold_label, span_start, span_end = row.rstrip().split('\\t')\n",
    "            articles_id.append(article_id)\n",
    "            gold_labels.append((gold_label, int(span_start), int(span_end)))\n",
    "    return articles_id, gold_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38dcd5af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T11:05:13.247686Z",
     "start_time": "2021-10-08T11:05:13.223690Z"
    }
   },
   "outputs": [],
   "source": [
    "def label(text, gt_labels):\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    special_symbols = \"\"\"!\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~ \\n\\t\\'\\\\\"\"\"\n",
    "    word = ''\n",
    "    inside = False\n",
    "    word_start = 0\n",
    "    for i in range(len(text)):\n",
    "        if text[i] in special_symbols:\n",
    "            if len(word) > 1:\n",
    "                tokens.append(word)\n",
    "                word = ''\n",
    "                if inside:\n",
    "                    if gt_labels[0][1] == word_start:\n",
    "                        labels.append(2)\n",
    "                    else:\n",
    "                        labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "        else:\n",
    "            if len(word) == 0:\n",
    "                word_start = i\n",
    "            word += text[i]\n",
    "        if len(gt_labels) > 0:\n",
    "            if i == gt_labels[0][1]:\n",
    "                inside = True\n",
    "            elif i == gt_labels[0][2] + 1:\n",
    "                inside = False\n",
    "                gt_labels.pop(0)\n",
    "    return tokens, labels\n",
    "    \n",
    "\n",
    "def create_dataset():\n",
    "    '''\n",
    "    Creates the dataset from the files contained in 'datasets/train-articles/' folder\n",
    "    \n",
    "    texts : list, each represents one article and contains\n",
    "    '''\n",
    "    texts = []\n",
    "    labels = []\n",
    "    articles = read_articles_from_file_list('datasets/train-articles/')\n",
    "    article_names = list(articles.keys())\n",
    "    prefix_lbl = 'datasets/train-labels-task-flc-tc/article'\n",
    "    postfix_lbl = '.task-flc-tc.labels'\n",
    "    for name in article_names:\n",
    "        articles_id, gold_labels = read_predictions_from_file(prefix_lbl + name + postfix_lbl)\n",
    "        gt_labels = []\n",
    "        for i in range(len(gold_labels)):\n",
    "            if gold_labels[i][0] == 'Loaded_Language':\n",
    "                gt_labels.append(gold_labels[i])\n",
    "        gt_labels.sort(key=lambda x: x[1])\n",
    "        tokens, lbls = label(articles[name], gt_labels)\n",
    "        texts.append(tokens)\n",
    "        labels.append(lbls)\n",
    "    \n",
    "    return texts, labels, article_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c405a7dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T11:05:15.007427Z",
     "start_time": "2021-10-08T11:05:13.841850Z"
    }
   },
   "outputs": [],
   "source": [
    "texts, labels, article_names = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1283dc50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T11:13:32.740643Z",
     "start_time": "2021-10-08T11:13:32.716849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Next',\n",
       " 'plague',\n",
       " 'outbreak',\n",
       " 'in',\n",
       " 'Madagascar',\n",
       " 'could',\n",
       " 'be',\n",
       " 'stronger',\n",
       " 'WHO',\n",
       " 'Geneva',\n",
       " 'The',\n",
       " 'World',\n",
       " 'Health',\n",
       " 'Organisation',\n",
       " 'chief',\n",
       " 'on',\n",
       " 'Wednesday',\n",
       " 'said',\n",
       " 'adeadly',\n",
       " 'plague',\n",
       " 'epidemic',\n",
       " 'appeared',\n",
       " 'to',\n",
       " 'have',\n",
       " 'been',\n",
       " 'brought',\n",
       " 'under',\n",
       " 'control',\n",
       " 'in',\n",
       " 'Madagascar',\n",
       " 'but',\n",
       " 'warned',\n",
       " 'the',\n",
       " 'next',\n",
       " 'outbreak',\n",
       " 'would',\n",
       " 'likely',\n",
       " 'be',\n",
       " 'stronger',\n",
       " 'The',\n",
       " 'next',\n",
       " 'transmission',\n",
       " 'could',\n",
       " 'be',\n",
       " 'more',\n",
       " 'pronounced',\n",
       " 'or',\n",
       " 'stronger',\n",
       " 'WHO',\n",
       " 'Director',\n",
       " 'General',\n",
       " 'Tedros',\n",
       " 'Adhanom',\n",
       " 'Ghebreyesus',\n",
       " 'told',\n",
       " 'reporters',\n",
       " 'in',\n",
       " 'Geneva',\n",
       " 'insisting',\n",
       " 'that',\n",
       " 'the',\n",
       " 'issue',\n",
       " 'is',\n",
       " 'serious',\n",
       " 'An',\n",
       " 'outbreak',\n",
       " 'of',\n",
       " 'both',\n",
       " 'bubonic',\n",
       " 'plague',\n",
       " 'which',\n",
       " 'is',\n",
       " 'spread',\n",
       " 'by',\n",
       " 'infected',\n",
       " 'rats',\n",
       " 'via',\n",
       " 'flea',\n",
       " 'bites',\n",
       " 'and',\n",
       " 'pneumonic',\n",
       " 'plague',\n",
       " 'spread',\n",
       " 'person',\n",
       " 'to',\n",
       " 'person',\n",
       " 'has',\n",
       " 'killed',\n",
       " 'more',\n",
       " 'than',\n",
       " '200',\n",
       " 'people',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Indian',\n",
       " 'Ocean',\n",
       " 'island',\n",
       " 'nation',\n",
       " 'since',\n",
       " 'August',\n",
       " 'Madagascar',\n",
       " 'has',\n",
       " 'suffered',\n",
       " 'bubonic',\n",
       " 'plague',\n",
       " 'outbreaks',\n",
       " 'almost',\n",
       " 'every',\n",
       " 'year',\n",
       " 'since',\n",
       " '1980',\n",
       " 'often',\n",
       " 'caused',\n",
       " 'by',\n",
       " 'rats',\n",
       " 'fleeing',\n",
       " 'forest',\n",
       " 'fires',\n",
       " 'The',\n",
       " 'disease',\n",
       " 'tends',\n",
       " 'to',\n",
       " 'make',\n",
       " 'acomeback',\n",
       " 'each',\n",
       " 'hot',\n",
       " 'rainy',\n",
       " 'season',\n",
       " 'from',\n",
       " 'September',\n",
       " 'to',\n",
       " 'April',\n",
       " 'On',\n",
       " 'average',\n",
       " 'between',\n",
       " '300',\n",
       " 'and',\n",
       " '600',\n",
       " 'infections',\n",
       " 'are',\n",
       " 'recorded',\n",
       " 'every',\n",
       " 'year',\n",
       " 'among',\n",
       " 'apopulation',\n",
       " 'approaching',\n",
       " '25',\n",
       " 'million',\n",
       " 'people',\n",
       " 'according',\n",
       " 'to',\n",
       " 'aUN',\n",
       " 'estimate',\n",
       " 'But',\n",
       " 'Tedros',\n",
       " 'voiced',\n",
       " 'alarm',\n",
       " 'that',\n",
       " 'plague',\n",
       " 'in',\n",
       " 'Madagascar',\n",
       " 'behaved',\n",
       " 'in',\n",
       " 'avery',\n",
       " 'very',\n",
       " 'different',\n",
       " 'way',\n",
       " 'this',\n",
       " 'year',\n",
       " 'Cases',\n",
       " 'sprang',\n",
       " 'up',\n",
       " 'far',\n",
       " 'earlier',\n",
       " 'than',\n",
       " 'usual',\n",
       " 'and',\n",
       " 'instead',\n",
       " 'of',\n",
       " 'being',\n",
       " 'confined',\n",
       " 'to',\n",
       " 'the',\n",
       " 'countryside',\n",
       " 'the',\n",
       " 'disease',\n",
       " 'infiltrated',\n",
       " 'towns',\n",
       " 'The',\n",
       " 'authorities',\n",
       " 'recorded',\n",
       " 'more',\n",
       " 'than',\n",
       " '2000',\n",
       " 'cases',\n",
       " 'and',\n",
       " 'Tedros',\n",
       " 'said',\n",
       " 'Wednesday',\n",
       " 'the',\n",
       " 'death',\n",
       " 'toll',\n",
       " 'stood',\n",
       " 'at',\n",
       " '207',\n",
       " 'He',\n",
       " 'also',\n",
       " 'pointed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'presence',\n",
       " 'of',\n",
       " 'the',\n",
       " 'pneumonic',\n",
       " 'version',\n",
       " 'which',\n",
       " 'spreads',\n",
       " 'more',\n",
       " 'easily',\n",
       " 'and',\n",
       " 'is',\n",
       " 'more',\n",
       " 'virulent',\n",
       " 'in',\n",
       " 'the',\n",
       " 'latest',\n",
       " 'outbreak',\n",
       " 'He',\n",
       " 'praised',\n",
       " 'the',\n",
       " 'rapid',\n",
       " 'response',\n",
       " 'from',\n",
       " 'WHO',\n",
       " 'and',\n",
       " 'Madagascar',\n",
       " 'authorities',\n",
       " 'that',\n",
       " 'helped',\n",
       " 'bring',\n",
       " 'the',\n",
       " 'outbreak',\n",
       " 'under',\n",
       " 'control',\n",
       " 'but',\n",
       " 'warned',\n",
       " 'that',\n",
       " 'the',\n",
       " 'danger',\n",
       " 'was',\n",
       " 'not',\n",
       " 'over',\n",
       " 'The',\n",
       " 'larger',\n",
       " 'than',\n",
       " 'usual',\n",
       " 'outbreak',\n",
       " 'had',\n",
       " 'helped',\n",
       " 'spread',\n",
       " 'the',\n",
       " 'bacteria',\n",
       " 'that',\n",
       " 'causes',\n",
       " 'the',\n",
       " 'plague',\n",
       " 'more',\n",
       " 'widely',\n",
       " 'This',\n",
       " 'along',\n",
       " 'with',\n",
       " 'poor',\n",
       " 'sanitation',\n",
       " 'and',\n",
       " 'vector',\n",
       " 'control',\n",
       " 'on',\n",
       " 'Madagascar',\n",
       " 'meant',\n",
       " 'that',\n",
       " 'when',\n",
       " 'the',\n",
       " 'plague',\n",
       " 'comes',\n",
       " 'again',\n",
       " 'it',\n",
       " 'starts',\n",
       " 'from',\n",
       " 'more',\n",
       " 'stock',\n",
       " 'and',\n",
       " 'the',\n",
       " 'magnitude',\n",
       " 'in',\n",
       " 'the',\n",
       " 'next',\n",
       " 'transmission',\n",
       " 'could',\n",
       " 'be',\n",
       " 'higher',\n",
       " 'than',\n",
       " 'the',\n",
       " 'one',\n",
       " 'that',\n",
       " 'we',\n",
       " 'saw',\n",
       " 'Tedros',\n",
       " 'said',\n",
       " 'That',\n",
       " 'means',\n",
       " 'that',\n",
       " 'Madagascar',\n",
       " 'could',\n",
       " 'be',\n",
       " 'affected',\n",
       " 'more',\n",
       " 'and',\n",
       " 'not',\n",
       " 'only',\n",
       " 'that',\n",
       " 'it',\n",
       " 'could',\n",
       " 'even',\n",
       " 'spill',\n",
       " 'over',\n",
       " 'into',\n",
       " 'neighbouring',\n",
       " 'countries',\n",
       " 'and',\n",
       " 'beyond',\n",
       " 'he',\n",
       " 'warned',\n",
       " 'Complicating',\n",
       " 'vector',\n",
       " 'control',\n",
       " 'is',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'the',\n",
       " 'fleas',\n",
       " 'that',\n",
       " 'carry',\n",
       " 'the',\n",
       " 'Yersinia',\n",
       " 'pestis',\n",
       " 'bacteria',\n",
       " 'that',\n",
       " 'causes',\n",
       " 'the',\n",
       " 'plague',\n",
       " 'have',\n",
       " 'proven',\n",
       " 'to',\n",
       " 'be',\n",
       " 'widely',\n",
       " 'resistant',\n",
       " 'to',\n",
       " 'chemicals',\n",
       " 'and',\n",
       " 'insecticides',\n",
       " 'That',\n",
       " 'sa',\n",
       " 'dangerous',\n",
       " 'combination',\n",
       " 'Tedros',\n",
       " 'said']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9667318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T11:14:10.047406Z",
     "start_time": "2021-10-08T11:14:10.023769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c221a365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
